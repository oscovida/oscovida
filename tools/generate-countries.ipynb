{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import ipynb_py_convert\n",
    "import nbformat\n",
    "import numpy as np\n",
    "from nbconvert import HTMLExporter\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from nbconvert.writers import FilesWriter\n",
    "\n",
    "from itertools import compress\n",
    "import functools\n",
    "import concurrent.futures\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from report_generators.reporters import CountryReport, GermanyReport, USAReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Crappy solution to me not knowing how to use concurrent futures rigth\n",
    "global shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Set to false if you do not want multiprocessing enabled\n",
    "workers = 16 #'auto'\n",
    "\n",
    "if workers == 'auto':\n",
    "    workers = max(1, cpu_count())\n",
    "    # try at most 4 to reduce probability of error message like\n",
    "    # the one shown at https://github.com/jupyter/jupyter_client/issues/541\n",
    "    workers = min(cores, 4)\n",
    "\n",
    "\n",
    "if workers:\n",
    "    print(f'Using {workers} processes')\n",
    "    \n",
    "wwwroot = \"wwwroot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "from coronavirus import *\n",
    "from coronavirus import MetadataRegion\n",
    "\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)  #  Disable pandas scientific notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning of cache and copying files has moved to\n",
    "\n",
    "- `generate-webpage-clean-setup.py` and \n",
    "- `generate-webpage-clean-setup.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_PREFIX = \"Tracking plots: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, c = fetch_deaths(), fetch_cases()\n",
    "\n",
    "countries = d.index\n",
    "countries2 = c.index\n",
    "assert (countries2 == countries).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_US_cases = fetch_cases_US()\n",
    "data_US_deaths = fetch_deaths_US()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also fetch data from Germany, so it is available later from the cache\n",
    "germany = fetch_data_germany()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_wwwroot_exist(wwwroot):\n",
    "    if not os.path.exists(wwwroot):\n",
    "        msg = \"To put the html into github repo for webhosting, run \"\n",
    "        msg += '\"git clone git@github.com:oscovida/oscovida.github.io.git wwwroot\" or similar'\n",
    "        # os.mkdir(wwwroot)\n",
    "        raise ValueError(f\"directory {wwwroot} missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Page Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_markdown_index_list(category):\n",
    "    \"\"\"Assemble a markdown table like this:\n",
    "    \n",
    "    | Country/Region                       | Total cases   | Total deaths   |\n",
    "    |:-------------------------------------|:--------------|:---------------|\n",
    "    | [Afghanistan](html/Afghanistan.html) | 1,351         | 43             |\n",
    "    | [Albania](html/Albania.html)         | 678           | 27             |\n",
    "    | [Algeria](html/Algeria.html)         | 3,127         | 415            |\n",
    "    | [Andorra](html/Andorra.html)         | 731           | 40             |\n",
    "    \n",
    "    and return as string.\n",
    "    \"\"\"\n",
    "    \n",
    "    known_categories = [\"world\", \"Germany\", \"US\"]\n",
    "\n",
    "    # gather data\n",
    "    regions_all = MetadataRegion.get_all_as_dataframe()\n",
    "    if category in known_categories:\n",
    "        # select those we are interested in\n",
    "        regions = regions_all[regions_all['category'] == category]\n",
    "    elif category in [\"all-regions\"]:\n",
    "        regions = regions_all\n",
    "    else:\n",
    "        \n",
    "        raise NotImplementedError(f\"category {category} is unknown.\"+\n",
    "                                  f\" Known values are {known_categories + ['all-regions']}\")\n",
    "    \n",
    "    # change index to contain URLs and one-line summary in markdown syntax\n",
    "    def compose_md_url(x):\n",
    "        one_line_summary, html = x\n",
    "        if isinstance(html, str):\n",
    "            return \"[\" + one_line_summary + \"](\" + os.path.join('html', html) +\")\"\n",
    "        elif repr(html) == 'nan':   # if html was not produced, then variable html is np.nan\n",
    "            print(f\"Missing html for {one_line_summary} - will not add link to html: \\n{x}\")\n",
    "            return one_line_summary\n",
    "        else:\n",
    "            raise NotImplementedError(\"Don't know how to proceed: \", one_line_summary, html, x)\n",
    "\n",
    "    new_index = regions[['one-line-summary', 'html-file']].apply(compose_md_url, axis=1)\n",
    "    regions2 = regions.set_index(new_index)\n",
    "    regions2.index.name = \"Location\"\n",
    "    \n",
    "    # select columns\n",
    "    regions3 = regions2[['max-cases', 'max-deaths', 'cases-last-week']]\n",
    "    regions4 = regions3.applymap(lambda v: '{:,}'.format(v))  # Thousands comma separator\n",
    "    \n",
    "    # rename columns\n",
    "    rename_dict = {'max-cases' : 'Total cases', \n",
    "                   'max-deaths' : 'Total deaths',\n",
    "                   'cases-last-week' : 'New cases last week'}\n",
    "    regions5 = regions4.rename(columns=rename_dict)\n",
    "\n",
    "    return regions5.to_markdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_markdown_index_page(md_content, title, pelican_file_path, \n",
    "                               save_as, wwwroot, slug=None):\n",
    "    \"\"\"Create pelican markdown file, like this:\n",
    "    \n",
    "    title: Germany\n",
    "    tags: Data, Plots, Germany\n",
    "    save-as: germany\n",
    "    date: 2020-04-11 08:00\n",
    "    \"\"\"\n",
    "\n",
    "    if slug is None:\n",
    "        slug = save_as\n",
    "    \n",
    "    with open(os.path.join(pelican_file_path), \"tw\") as f:\n",
    "        f.write(f\"title: {title}\\n\")\n",
    "        # f.write(f\"category: Data\\n\")  - have stopped using categories (22 April 2020)\n",
    "        f.write(f\"tags: Data, Plots, {title}\\n\")\n",
    "        f.write(f\"save-as: {save_as}\\n\")\n",
    "        f.write(f\"slug: {slug}\\n\")\n",
    "        date_time = datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M\")\n",
    "        f.write(f\"date: {date_time}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(md_content)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_page(sections, rootname, wwwroot):\n",
    "    \"\"\"Sections is dictionary: key is title, value is markdown text\"\"\"\n",
    "    md_file = rootname + \".md\"\n",
    "    \n",
    "    with open(os.path.join(wwwroot, md_file), \"tw\") as f:\n",
    "        for section in sections:\n",
    "            f.write(f\"# {section}\\n\\n\")\n",
    "            f.write(sections[section])\n",
    "    print(f\"Written overview to {md_file}.\")\n",
    "    html_file = rootname + \".html\"\n",
    "    subprocess.check_call(f\"pandoc -t html -o {os.path.join(wwwroot, html_file)} \" +\n",
    "                          f\"{os.path.join(wwwroot, md_file)}\", shell=True)\n",
    "    return html_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial and Parallel Report Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_html_report_single(region, *,\n",
    "                              Reporter, wwwroot,\n",
    "                              expiry_hours=2, attempts=3, force=False, verbose=False):\n",
    "    for attempt in range(attempts):\n",
    "        if 'shutdown' in globals() and shutdown:\n",
    "            raise KeyboardInterrupt\n",
    "        try:\n",
    "            report = Reporter(region, wwwroot=wwwroot, verbose=verbose)\n",
    "            if report.metadata.last_updated_hours_ago() < expiry_hours and not force:\n",
    "                continue\n",
    "            report.generate()\n",
    "        except Exception as e:\n",
    "            if type(e) == KeyboardInterrupt:\n",
    "                raise e\n",
    "            if attempt+1 == attempts:\n",
    "                print(f\"Error for {region}\")\n",
    "                print(e)\n",
    "                raise e\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_html_reports_serial(regions, *,\n",
    "                               Reporter, wwwroot,\n",
    "                               expiry_hours=2, attempts=3, force=False, verbose=False):\n",
    "    pbar = trange(len(regions))\n",
    "    for i in pbar:\n",
    "        region = regions[i]\n",
    "        region_str = region[-1] if type(region) == list else region\n",
    "        pbar.set_description(f\"Processing {region_str}\")\n",
    "        create_html_report_single(region,\n",
    "                                  Reporter=Reporter, wwwroot=wwwroot,\n",
    "                                  attempts=attempts, force=force, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_html_reports_parallel(regions, workers, pool, *,\n",
    "                                 Reporter, wwwroot,\n",
    "                                 expiry_hours=2, attempts=3, force=False, verbose=False):\n",
    "    padding = workers - (len(regions) % workers)\n",
    "    regions = regions + ([None] * padding)\n",
    "    per_worker = int(len(regions)/workers)\n",
    "    #  Weird way to create an evenly distributed list\n",
    "    regions_per_worker = [[] for p in range(workers)]\n",
    "    [regions_per_worker[w].append(r) for w, r in list(zip(list(range(workers))*per_worker, regions))]\n",
    "    regions_per_worker = [list(filter(None.__ne__, worker)) for worker in regions_per_worker]\n",
    "    \n",
    "    print(f\"Using {workers} workers with tasks:\")\n",
    "    for n in range(workers):\n",
    "        if len(regions_per_worker[n]) > 5:\n",
    "            print(f\"\\t{n}: {len(regions_per_worker[n])} regions...\")\n",
    "        else:\n",
    "            print(f\"\\t{n}: {regions_per_worker[n]}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    wrapper = functools.partial(create_html_reports_serial,\n",
    "                                Reporter=Reporter, wwwroot=wwwroot,\n",
    "                                attempts=attempts, force=force, verbose=verbose)\n",
    "\n",
    "    pool.map(wrapper, regions_per_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_html_reports(*, Reporter, regions, wwwroot,\n",
    "                        expiry_hours=2, attempts=3, force=False, verbose=False,\n",
    "                        workers=None):\n",
    "    if workers:\n",
    "        #  Works with both ThreadPoolExecutor and ProcessPoolExecutor\n",
    "        #  for this task multithreading and multiprocessing perform\n",
    "        #  about the same\n",
    "        with ThreadPoolExecutor(max_workers=workers) as pool:\n",
    "            create_html_reports_parallel(\n",
    "                regions, workers, pool,\n",
    "                Reporter=Reporter, wwwroot=wwwroot,\n",
    "                expiry_hours=expiry_hours, attempts=attempts, force=force, verbose=verbose)\n",
    "\n",
    "    else:\n",
    "        create_html_reports_serial(regions,\n",
    "                                   Reporter=Reporter, wwwroot=wwwroot,\n",
    "                                   expiry_hours=expiry_hours, attempts=attempts, force=force, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_list():\n",
    "    d, c = fetch_deaths(), fetch_cases()\n",
    "\n",
    "    countries = d.index\n",
    "    countries2 = c.index\n",
    "    assert (countries2 == countries).all()\n",
    "    \n",
    "    # Here we should identify regions in countries, and process those.\n",
    "    # Instead, as a quick hack to get started, we'll just take one country\n",
    "    # and the current \"get_country\" method will sum over all regions of one country if only \n",
    "    # the country name is given.\n",
    "    \n",
    "    return sorted(countries.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = get_country_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This used to be in `create_html_reports` wrapping the executor, didn't work\n",
    "#  but it does work here so... *shrug*\n",
    "try:\n",
    "    create_html_reports(\n",
    "            Reporter=CountryReport, regions=countries,\n",
    "            wwwroot=wwwroot, workers=workers,\n",
    "        )\n",
    "except KeyboardInterrupt:\n",
    "    shutdown = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_md = create_markdown_index_list(\"world\")\n",
    "\n",
    "create_markdown_index_page(\n",
    "    index_md, title=TITLE_PREFIX + \" Countries of the world\", \n",
    "    pelican_file_path=\"pelican/content/countries.md\", save_as=\"countries\", \n",
    "    wwwroot=wwwroot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Germany Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_germany_regions_list():\n",
    "    data_germany = fetch_data_germany()\n",
    "    land_kreis = data_germany[['Bundesland', 'Landkreis']]\n",
    "    ordered = land_kreis.sort_values(['Bundesland', 'Landkreis'])\n",
    "    return ordered.drop_duplicates().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "germany_regions = get_germany_regions_list()\n",
    "wwwroot = \"wwwroot\"\n",
    "\n",
    "# data cleaning: on 13 April, we had a Landkreis \"LK GÃ¶ttingen (alt)\"\n",
    "# with only one data point. This causes plots to fail, because there\n",
    "# is nothing to plot, and then the legend() command failed.\n",
    "# We assume that the RKI labels unusual data with '(alt)', and remove those.\n",
    "\n",
    "alt_data_sets = [\"(alt)\" in r[1].lower() for r in germany_regions]\n",
    "if sum(alt_data_sets) > 0:\n",
    "    bad_datasests = list(compress(germany_regions, alt_data_sets))\n",
    "    \n",
    "    print(f\"Removing datasets label with '(alt)': {bad_datasests}\")\n",
    "\n",
    "    for bd in bad_datasests:\n",
    "        c, d, _ = germany_get_region(landkreis=bd[1])\n",
    "        print(f\"\\tremoved: {bd} : len(cases)={len(c)}, len(deaths)={len(d)}\")\n",
    "\n",
    "    bad_indecies = list(compress(range(len(alt_data_sets)), alt_data_sets))\n",
    "\n",
    "    [germany_regions.pop(i) for i in bad_indecies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This used to be in `create_html_reports` wrapping the executor, didn't work\n",
    "#  but it does work here so... *shrug*\n",
    "try:\n",
    "    shutdown = False\n",
    "    create_html_reports(\n",
    "            Reporter=GermanyReport, regions=germany_regions,\n",
    "            wwwroot=wwwroot, workers=workers,\n",
    "        )\n",
    "except KeyboardInterrupt:\n",
    "    shutdown = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_md = create_markdown_index_list(category=\"Germany\")\n",
    "\n",
    "create_markdown_index_page(\n",
    "    index_md, title= TITLE_PREFIX + \" Germany\", \n",
    "    pelican_file_path=\"pelican/content/germany.md\", save_as=\"germany\", \n",
    "    wwwroot=wwwroot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USA Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = get_US_region_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This used to be in `create_html_reports` wrapping the executor, didn't work\n",
    "#  but it does work here so... *shrug*\n",
    "try:\n",
    "    shutdown = False\n",
    "    create_html_reports(\n",
    "            Reporter=USAReport, regions=states,\n",
    "            wwwroot=wwwroot, workers=workers,\n",
    "        )\n",
    "except KeyboardInterrupt:\n",
    "    shutdown = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_md = create_markdown_index_list(\"US\")\n",
    "\n",
    "create_markdown_index_page(\n",
    "    index_md, title=TITLE_PREFIX + \" United States\", \n",
    "    pelican_file_path=\"pelican/content/US.md\", save_as=\"us\", \n",
    "    wwwroot=wwwroot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Pages for All Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_md = create_markdown_index_list(\"all-regions\")\n",
    "create_markdown_index_page(\n",
    "    index_md, title=TITLE_PREFIX + \" All regions and countries\", \n",
    "    pelican_file_path=\"pelican/content/all-regions.md\", save_as=\"all-regions\", \n",
    "    wwwroot=wwwroot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MetadataRegion.get_all()\n",
    "for name in ms:\n",
    "    m = MetadataRegion(name)\n",
    "    dt = m.last_updated_hours_ago()\n",
    "    if dt > 2:\n",
    "        print(f\"Problem with '{name}', last update: {dt} ago \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oscovida",
   "language": "python",
   "name": "oscovida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
