{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note book to create html pages for countries and Kreise in Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New strategy (with pelican)\n",
    "\n",
    "- put notebooks into wwwroot/ipynb folder\n",
    "- put html into html wwwroot/folder\n",
    "- pelican files can then go into wwwroot folder\n",
    "\n",
    "Advantages:\n",
    "- cleaner than all in one folder\n",
    "- github can display all files in each subdirectory (there is a limit of 500 files or so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '../coronavirus.py': No such file or directory\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[Memory(location=./cachedir/joblib)]: Flushing completely the cache\n"
     ]
    }
   ],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%cp -v ../coronavirus.py .\n",
    "from coronavirus import *\n",
    "# force download of new data\n",
    "clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also delete date in place where notebooks are executed\n",
    "!rm -rf wwwroot/ipynb/cachedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data: last data point 4/15/20 from https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\n",
      "Downloaded data: last data point 4/15/20 from https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\n"
     ]
    }
   ],
   "source": [
    "d, c = fetch_deaths(), fetch_cases()\n",
    "\n",
    "countries = d.index\n",
    "countries2 = c.index\n",
    "assert (countries2 == countries).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_template(templatefile, output_file_name, mappings, wwwroot):\n",
    "    \"\"\"Create concrete *.ipynb file from template\n",
    "    - templatefile: the template with placeholders to be substituted\n",
    "    - mappings: dictiorany with placeholders as keys, and values to be substituted\n",
    "    - output_file_name: name to write modified file to\n",
    "    - wwwroot: directory in which the output file should be written\n",
    "    \"\"\"\n",
    "    # open template\n",
    "    with open(templatefile, \"tr\") as f_template:\n",
    "        template = f_template.read()\n",
    "    for key in mappings:\n",
    "        template = template.replace(key, mappings[key])\n",
    "    with open(os.path.join(wwwroot, output_file_name), \"tw\") as f:\n",
    "        f.write(template)\n",
    "    print(f\"Written file to {output_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please be patient - downloading data from https://opendata.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0.csv ...\n",
      "Completed downloading 71100 rows in 3.1 seconds.\n"
     ]
    }
   ],
   "source": [
    "def check_country_name_is_known(name):\n",
    "    d = fetch_deaths()\n",
    "    assert name in d.index, f\"{name} is unknown. Known countries are {sorted(d.index)}\"\n",
    "\n",
    "def germany_check_region_name_is_known(name):\n",
    "    d = fetch_data_germany()\n",
    "    assert name in list(d['Bundesland'].drop_duplicates()), \\\n",
    "        f\"{name} is unknown. Known regions are {sorted(list(d['Bundesland'].drop_duplicates()))}\"\n",
    "\n",
    "def germany_check_subregion_name_is_known(name):\n",
    "    d = fetch_data_germany()\n",
    "    assert name in list(d['Landkreis'].drop_duplicates()), \\\n",
    "        f\"{name} is unknown. Known regions are {sorted(list(d['Landkreis'].drop_duplicates()))}\"\n",
    "\n",
    "germany_check_region_name_is_known(\"Hamburg\") \n",
    "germany_check_subregion_name_is_known(\"SK Hamburg\") \n",
    "\n",
    "    \n",
    "def sanitise(name):\n",
    "    \"\"\"Given a country name as a string, sanitise it for use as URL and filename: \n",
    "    - get rid of spaces, commas\n",
    "    \n",
    "    return cleaned string.\n",
    "    \n",
    "    (Leave umlaute for now)\n",
    "    \"\"\"\n",
    "    s = name.replace(\" \", \"-\")\n",
    "    s = s.replace(\",\", \"-\")\n",
    "    return s\n",
    "    \n",
    "    \n",
    "def get_binder_url(notebook):\n",
    "    \"\"\"Given a notebook name, compute the path\"\"\"\n",
    "    base = \"https://mybinder.org/v2/gh/fangohr/coronavirus/master?filepath=ipynb/\"\n",
    "    return base + notebook.replace(\" \", \"%20\")\n",
    "\n",
    "\n",
    "def create_ipynb_for_country(country, templatename, wwwroot):\n",
    "    \"\"\"Creates ipynb file for country, based on templatename. \n",
    "    File is based in ipynb subfolder of wwwroot.\n",
    "    Returns name of file.\"\"\"\n",
    "    \n",
    "    # create ipynb folder if required\n",
    "    ipynb_dir = os.path.join(wwwroot, \"ipynb\")\n",
    "    if not os.path.exists(ipynb_dir):\n",
    "        os.mkdir(ipynb_dir)\n",
    "        \n",
    "    \n",
    "    check_country_name_is_known(country)\n",
    "    \n",
    "    output_file_name =  f\"{country}.ipynb\"\n",
    "    output_file_path = os.path.join(wwwroot, \"ipynb\", output_file_name)\n",
    "    \n",
    "    # country = sanitize(country)\n",
    "    mappings = {\n",
    "        \"%title%\" : country,\n",
    "        \"%title2%\" : \"\",\n",
    "        \"%country%\" : country,\n",
    "        \"%binderurl%\" : get_binder_url(output_file_name),\n",
    "        \"%create_date%\" : datetime.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    }\n",
    "\n",
    "    modify_template(templatename, os.path.join(\"ipynb\", output_file_name), mappings, wwwroot)\n",
    "    assert os.path.exists(output_file_path), f\"{output_file_path} does not exist\"\n",
    "    return output_file_name\n",
    "\n",
    "def create_ipynb_for_germany(region, subregion, templatename, wwwroot):\n",
    "    \"\"\"Creates ipynb file for region and subregion in Germany, based on templatename. \n",
    "    File is based in ipynb subfolder of wwwroot.\n",
    "    Returns name of file.\"\"\"\n",
    "    germany_check_region_name_is_known(region)\n",
    "    germany_check_subregion_name_is_known(subregion)\n",
    "    \n",
    "    output_file_name =  f\"Germany-{sanitise(region)}-{sanitise(subregion)}.ipynb\"\n",
    "    output_file_path = os.path.join(wwwroot, \"ipynb\", output_file_name)\n",
    "    \n",
    "    # country = sanitize(country)\n",
    "    mappings = {\n",
    "        \"%title%\" : f\"Germany: {subregion} ({region})\",\n",
    "        \"%title2%\" : \"\",\n",
    "        \"%region%\" : region,\n",
    "        \"%subregion%\" : subregion,\n",
    "        \"%binderurl%\" : get_binder_url(output_file_name),\n",
    "        \"%create_date%\" : datetime.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    }\n",
    "\n",
    "    modify_template(templatename, os.path.join(\"ipynb\", output_file_name), mappings, wwwroot)\n",
    "    assert os.path.exists(output_file_path), f\"{output_file_path} does not exist\"\n",
    "    return output_file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def nbconvert_ipynb2html(ipynb_name, wwwroot):\n",
    "    \"\"\"Given the name of a a notebook (such as \"germany.ipynb\"), create the \n",
    "    corresponding html file (\"html/germany.html\") from the notebook file in \n",
    "    \"ipynb\" and return the name of the file (i.e. germany.html).\n",
    "    \"\"\"\n",
    "    ipynb_dir = os.path.join(wwwroot, \"ipynb\")\n",
    "#     os.symlink('..', ipynb_dir)\n",
    "    \n",
    "    # copy file to run the notebook\n",
    "#     command = f\"cp -fv ./coronavirus.py {ipynb_dir}\"\n",
    "#     subprocess.check_call(command, shell=True)\n",
    "    \n",
    "    # copy requirements (needed for binder)\n",
    "#     command = f\"cp -fv ../requirements.txt {wwwroot}\"\n",
    "#     subprocess.check_call(command, shell=True)\n",
    "    subprocess.check_call(['pip', 'install', '..'])\n",
    "    \n",
    "    # execute notebook and create html copy from it\n",
    "    command = (\n",
    "        f'jupyter-nbconvert \"{os.path.join(ipynb_dir, ipynb_name)}\" '\n",
    "        f'--to html --execute --output-dir {os.path.join(wwwroot, \"html\")}'\n",
    "    )\n",
    "    print(f\"Command = {command}\")\n",
    "    output = subprocess.check_call(command, shell=True)\n",
    "\n",
    "    # compute output path\n",
    "    output_file_name = os.path.splitext(ipynb_name)[0] + \".html\"\n",
    "    assert os.path.exists(os.path.join(wwwroot, \"html\", output_file_name))\n",
    "    \n",
    "    return output_file_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_md_index_list(title, links):\n",
    "    \"\"\"Turn dictionary of links into markdown string\"\"\"\n",
    "    lines = []\n",
    "    lines.append(title)\n",
    "    lines.append(\"\")   # need empty line for markdown syntax\n",
    "    for name, (name_html, name_ipynb) in links.items():\n",
    "        path_html = os.path.join('html', name_html)\n",
    "        lines.append(f\"* [{name}]({path_html})\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def test_create_md_index_list():\n",
    "    title = \"Title\"\n",
    "    links = {\"France\" : (\"France.html\", \"France.ipynb\")}\n",
    "    assert create_md_index_list(title, links) == \"Title\\n\\n* [France](html/France.html)\"\n",
    "    \n",
    "test_create_md_index_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_list():\n",
    "    d, c = fetch_deaths(), fetch_cases()\n",
    "\n",
    "    countries = d.index\n",
    "    countries2 = c.index\n",
    "    assert (countries2 == countries).all()\n",
    "    \n",
    "    # Here we should identify regions in countries, and process those.\n",
    "    # Instead, as a quick hack to get started, we'll just take one country\n",
    "    # and the current \"get_country\" method will sum over all regions of one country if only \n",
    "    # the country name is given.\n",
    "    \n",
    "    return sorted(countries.drop_duplicates())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_page(sections, rootname, wwwroot):\n",
    "    \"\"\"Sections is dictionary: key is title, value is markdown text\"\"\"\n",
    "    md_file = rootname + \".md\"\n",
    "    \n",
    "    with open(os.path.join(wwwroot, md_file), \"tw\") as f:\n",
    "        for section in sections:\n",
    "            f.write(f\"# {section}\\n\\n\")\n",
    "            f.write(sections[section])\n",
    "    print(f\"Written overview to {md_file}.\")\n",
    "    html_file = rootname + \".html\"\n",
    "    subprocess.check_call(f\"pandoc -t html -o {os.path.join(wwwroot, html_file)} \" +\n",
    "                          f\"{os.path.join(wwwroot, md_file)}\", shell=True)\n",
    "    return html_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_germany_subregion_list():\n",
    "    \"\"\"returns list of subregions (Kreise), \n",
    "    ordered according to (i) Land, then (ii) Kreis\n",
    "    \"\"\"\n",
    "    x = fetch_data_germany()\n",
    "    land_kreis = x[['Bundesland', 'Landkreis']]\n",
    "    ordered = land_kreis.sort_values(['Bundesland', 'Landkreis'])\n",
    "    return list(ordered['Landkreis'].drop_duplicates())\n",
    " \n",
    "\n",
    "@joblib_memory.cache\n",
    "def germany_get_bundesland_from_kreis(kreis):\n",
    "        x = fetch_data_germany()\n",
    "        return x[x['Landkreis'] == kreis].iloc[0]['Bundesland']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_wwwroot_exist(wwwroot):\n",
    "    if not os.path.exists(wwwroot):\n",
    "        msg = \"To put the html into github repo for webhosting, run \"\n",
    "        msg += '\"git clone git@github.com:fangohr/coronavirus.git wwwroot\" or similar'\n",
    "        # os.mkdir(wwwroot)\n",
    "        raise ValueError(f\"directory {wwwroot} missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_html_for_john_hopkins_countries(countries, wwwroot):\n",
    "    \"\"\"countries: list of strings with countrie names\n",
    "    \n",
    "    returns dictionary: keys are countrynames, values are tuples with path to html file and path to notebook\"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    does_wwwroot_exist(wwwroot)\n",
    "    \n",
    "    created_files = {}\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        print(f\"Processing {i+1}/{len(countries)} [{time.time()-start_time:4.0f}s]\")\n",
    "        ipynb_name = create_ipynb_for_country(country, \"template-country.ipynb\", wwwroot=wwwroot)\n",
    "        html_name = nbconvert_ipynb2html(ipynb_name, wwwroot=wwwroot)\n",
    "        created_files[country] = html_name, ipynb_name\n",
    "    print(\"Create {len(countries) notebooks and html versions in\" + \\\n",
    "          \"{time.time()-start_time} seconds}\")\n",
    "    return created_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_markdown_index_page(md_content, title, pelican_file_path, \n",
    "                               save_as, wwwroot):\n",
    "    \"\"\"Create pelican markdown file, like this:\n",
    "    \n",
    "    title: Germany\n",
    "    category: Data\n",
    "    tags: data, plots\n",
    "    save-as: germany\n",
    "    date: 2020-04-11 08:00\n",
    "    \"\"\"\n",
    "\n",
    "    with open(os.path.join(pelican_file_path), \"tw\") as f:\n",
    "        f.write(f\"title: {title}\\n\")\n",
    "        f.write(f\"category: Data\\n\")\n",
    "        f.write(f\"tags: data, plots\\n\")\n",
    "        f.write(f\"save-as: {save_as}\\n\")\n",
    "        date_time = datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M\")\n",
    "        f.write(f\"date: {date_time}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(md_content)\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create country overview for the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/185 [   0s]\n",
      "Written file to ipynb/Afghanistan.ipynb\n",
      "Command = jupyter-nbconvert \"wwwroot/ipynb/Afghanistan.ipynb\" --to html --execute --output-dir wwwroot/html\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'jupyter-nbconvert \"wwwroot/ipynb/Afghanistan.ipynb\" --to html --execute --output-dir wwwroot/html' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-09872263e2c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwwwroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"wwwroot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcountries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_country_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcreated_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_html_for_john_hopkins_countries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwwwroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mindex_md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_md_index_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Countries\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m create_markdown_index_page(index_md, title=\"World\", \n",
      "\u001b[0;32m<ipython-input-12-f982a8a03157>\u001b[0m in \u001b[0;36mcreate_html_for_john_hopkins_countries\u001b[0;34m(countries, wwwroot)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing {i+1}/{len(countries)} [{time.time()-start_time:4.0f}s]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mipynb_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ipynb_for_country\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"template-country.ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwwwroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwwwroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mhtml_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbconvert_ipynb2html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mipynb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwwwroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwwwroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mcreated_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipynb_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     print(\"Create {len(countries) notebooks and html versions in\" + \\\n",
      "\u001b[0;32m<ipython-input-6-7e7cb0d97b24>\u001b[0m in \u001b[0;36mnbconvert_ipynb2html\u001b[0;34m(ipynb_name, wwwroot)\u001b[0m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Command = {command}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# compute output path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'jupyter-nbconvert \"wwwroot/ipynb/Afghanistan.ipynb\" --to html --execute --output-dir wwwroot/html' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "wwwroot = \"wwwroot\"\n",
    "countries = get_country_list()\n",
    "created_files = create_html_for_john_hopkins_countries(countries, wwwroot)\n",
    "index_md = create_md_index_list(\"Countries\", created_files)\n",
    "create_markdown_index_page(index_md, title=\"World\", \n",
    "                           pelican_file_path=\"pelican/content/world.md\", save_as=\"world\", \n",
    "                           wwwroot=wwwroot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create list of Germany data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_html_for_Germany(subregions, wwwroot):\n",
    "    does_wwwroot_exist(wwwroot)\n",
    "    start_time = time.time()\n",
    "    created_files = {}\n",
    "\n",
    "    for i, kreis in enumerate(subregions):\n",
    "        bundesland = germany_get_bundesland_from_kreis(kreis)\n",
    "        print(f\"Processing {i+1}/{len(subregions)} [{time.time()-start_time:4.0f}s]\")\n",
    "        ipynb_name = create_ipynb_for_germany(region=bundesland, subregion=kreis, \n",
    "                                              templatename=\"template-germany.ipynb\", wwwroot=wwwroot)\n",
    "        html_name = nbconvert_ipynb2html(ipynb_name, wwwroot=wwwroot)\n",
    "        one_line_summary = f\"Germany: {bundesland} : {kreis}\"\n",
    "        created_files[one_line_summary] = html_name, ipynb_name\n",
    "        print(\"Create {len(subregions) notebooks and html versions in\" + \\\n",
    "              \"{time.time()-start_time} seconds}\")\n",
    "    return created_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwwroot = \"wwwroot\"\n",
    "subregions = get_germany_subregion_list()\n",
    "\n",
    "# data cleaning: on 13 April, we had a Landkreis \"LK Göttingen (alt)\"\n",
    "# with only one data point. This causes plots to fail, because there\n",
    "# is nothing to plot, and then the legend() command failed.\n",
    "# We assume that the RKI labels unusual data with '(alt)', and remove those.\n",
    "\n",
    "alt_data_sets = [x for x in subregions if \"(alt)\" in x.lower()]\n",
    "if len(alt_data_sets) > 0:\n",
    "    print(f\"Removing datasets label with '(alt)': {alt_data_sets}\")\n",
    "    for alt in alt_data_sets:\n",
    "        c, d = germany_get_region(landkreis=alt)\n",
    "        print(f\"  removed: {alt} : len(cases)={len(c)}, len(deaths)={len(d)}\")\n",
    "    subregions = [x for x in subregions if not \"(alt)\" in x.lower()]\n",
    "\n",
    "created_files = create_html_for_Germany(subregions, wwwroot)\n",
    "index_md = create_md_index_list(\"Landkreise in Germany\", \n",
    "                                created_files)\n",
    "create_markdown_index_page(index_md, title=\"Germany\", \n",
    "                           pelican_file_path=\"pelican/content/germany.md\", save_as=\"germany\", \n",
    "                           wwwroot=wwwroot)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, d = germany_get_region(landkreis='LK Göttingen (alt)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2, d2 = germany_get_region(landkreis='LK Göttingen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
